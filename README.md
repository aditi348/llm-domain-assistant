# ğŸ¤– LLM-Domain Assistant with Chat Memory & Embedding Visualization

This project is a lightweight and powerful **Retrieval-Augmented Generation (RAG)** system that lets you upload PDF documents, ask questions about their contents, and get instant, context-aware answers from an LLM â€” with memory support, summarization, and 2D embedding visualization.

---

## ğŸ” Features

- ğŸ“„ **Upload Multiple PDFs**
- ğŸ§  **Ask Questions with Memory** (Multi-turn chat)
- ğŸ“š **Retrieves Context** with FAISS and Sentence Transformers
- ğŸ§¾ **Summarizes Entire PDFs**
- ğŸ¯ **Visualize Embeddings** using UMAP to show semantic clustering
- âš¡ Uses **Open Source LLM via OpenRouter API** (Free to use, no paid key needed)
- ğŸ§© Modular design using `rag_engine.py`, `llm_interface.py`, and `app.py`

---

## ğŸ–¼ï¸ Demo Screenshot

![App Screenshot](assets/demo.png) <!-- Optional if you have one -->

---

## ğŸš€ Getting Started

### ğŸ”§ 1. Clone the Repository

```bash
git clone https://github.com/aditi348/llm-domain-assistant.git
cd llm-domain-assistant